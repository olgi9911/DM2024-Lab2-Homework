{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student Information\n",
    "Name: 林奕廷\n",
    "\n",
    "Student ID: 113062513\n",
    "\n",
    "GitHub ID: olgi9911\n",
    "\n",
    "Kaggle name: Oscar Lin\n",
    "\n",
    "Kaggle private scoreboard snapshot:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![leaderboard.png](./pics/leaderboard.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First: __This part is worth 30% of your grade.__ Do the **take home exercises** in the [DM2024-Lab2-master Repo](https://github.com/didiersalazar/DM2024-Lab2-Master). You may need to copy some cells from the Lab notebook to this notebook. \n",
    "\n",
    "\n",
    "2. Second: __This part is worth 30% of your grade.__ Participate in the in-class [Kaggle Competition](https://www.kaggle.com/competitions/dm-2024-isa-5810-lab-2-homework) regarding Emotion Recognition on Twitter by this link: https://www.kaggle.com/competitions/dm-2024-isa-5810-lab-2-homework. The scoring will be given according to your place in the Private Leaderboard ranking: \n",
    "    - **Bottom 40%**: Get 20% of the 30% available for this section.\n",
    "\n",
    "    - **Top 41% - 100%**: Get (0.6N + 1 - x) / (0.6N) * 10 + 20 points, where N is the total number of participants, and x is your rank. (ie. If there are 100 participants and you rank 3rd your score will be (0.6 * 100 + 1 - 3) / (0.6 * 100) * 10 + 20 = 29.67% out of 30%.)   \n",
    "    Submit your last submission **BEFORE the deadline (Nov. 26th, 11:59 pm, Tuesday)**. Make sure to take a screenshot of your position at the end of the competition and store it as '''pic0.png''' under the **img** folder of this repository and rerun the cell **Student Information**.\n",
    "    \n",
    "\n",
    "3. Third: __This part is worth 30% of your grade.__ A report of your work developing the model for the competition (You can use code and comment on it). This report should include what your preprocessing steps, the feature engineering steps and an explanation of your model. You can also mention different things you tried and insights you gained. \n",
    "\n",
    "\n",
    "4. Fourth: __This part is worth 10% of your grade.__ It's hard for us to follow if your code is messy :'(, so please **tidy up your notebook**.\n",
    "\n",
    "\n",
    "Upload your files to your repository then submit the link to it on the corresponding e-learn assignment.\n",
    "\n",
    "Make sure to commit and save your changes to your repository __BEFORE the deadline (Nov. 26th, 11:59 pm, Tuesday)__. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please refer to the master repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Begin Assignment Here\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data_id = pd.read_csv('dm-2024-isa-5810-lab-2-homework/data_identification.csv')\n",
    "emotion = pd.read_csv('dm-2024-isa-5810-lab-2-homework/emotion.csv')\n",
    "tweets = pd.read_json('dm-2024-isa-5810-lab-2-homework/tweets_DM.json', lines=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x376b20</td>\n",
       "      <td>People who post \"add me on #Snapchat\" must be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x2d5350</td>\n",
       "      <td>@brianklaas As we see, Trump is dangerous to #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x28b412</td>\n",
       "      <td>Confident of your obedience, I write to you, k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x1cd5b0</td>\n",
       "      <td>Now ISSA is stalking Tasha 😂😂😂 &lt;LH&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x2de201</td>\n",
       "      <td>\"Trust is not the same as faith. A friend is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867530</th>\n",
       "      <td>0x316b80</td>\n",
       "      <td>When you buy the last 2 tickets remaining for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867531</th>\n",
       "      <td>0x29d0cb</td>\n",
       "      <td>I swear all this hard work gone pay off one da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867532</th>\n",
       "      <td>0x2a6a4f</td>\n",
       "      <td>@Parcel2Go no card left when I wasn't in so I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867533</th>\n",
       "      <td>0x24faed</td>\n",
       "      <td>Ah, corporate life, where you can date &lt;LH&gt; us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867534</th>\n",
       "      <td>0x34be8c</td>\n",
       "      <td>Blessed to be living #Sundayvibes &lt;LH&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1867535 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tweet_id                                               text\n",
       "0        0x376b20  People who post \"add me on #Snapchat\" must be ...\n",
       "1        0x2d5350  @brianklaas As we see, Trump is dangerous to #...\n",
       "2        0x28b412  Confident of your obedience, I write to you, k...\n",
       "3        0x1cd5b0                Now ISSA is stalking Tasha 😂😂😂 <LH>\n",
       "4        0x2de201  \"Trust is not the same as faith. A friend is s...\n",
       "...           ...                                                ...\n",
       "1867530  0x316b80  When you buy the last 2 tickets remaining for ...\n",
       "1867531  0x29d0cb  I swear all this hard work gone pay off one da...\n",
       "1867532  0x2a6a4f  @Parcel2Go no card left when I wasn't in so I ...\n",
       "1867533  0x24faed  Ah, corporate life, where you can date <LH> us...\n",
       "1867534  0x34be8c             Blessed to be living #Sundayvibes <LH>\n",
       "\n",
       "[1867535 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract tweet_id and text from the _source column\n",
    "tweets_extracted = tweets['_source'].apply(lambda x: {'tweet_id': x['tweet']['tweet_id'], 'text': x['tweet']['text']})\n",
    "tweets_df = pd.json_normalize(tweets_extracted)\n",
    "\n",
    "tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>identification</th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x28cc61</td>\n",
       "      <td>test</td>\n",
       "      <td>@Habbo I've seen two separate colours of the e...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x29e452</td>\n",
       "      <td>train</td>\n",
       "      <td>Huge Respect🖒 @JohnnyVegasReal talking about l...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x2b3819</td>\n",
       "      <td>train</td>\n",
       "      <td>Yoooo we hit all our monthly goals with the ne...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x2db41f</td>\n",
       "      <td>test</td>\n",
       "      <td>@FoxNews @KellyannePolls No serious self respe...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x2a2acc</td>\n",
       "      <td>train</td>\n",
       "      <td>@KIDSNTS @PICU_BCH @uhbcomms @BWCHBoss Well do...</td>\n",
       "      <td>trust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867530</th>\n",
       "      <td>0x227e25</td>\n",
       "      <td>train</td>\n",
       "      <td>@BBCBreaking Such an inspirational talented pe...</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867531</th>\n",
       "      <td>0x293813</td>\n",
       "      <td>train</td>\n",
       "      <td>And still #libtards won't get off the guy's ba...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867532</th>\n",
       "      <td>0x1e1a7e</td>\n",
       "      <td>train</td>\n",
       "      <td>When you sow #seeds of service or hospitality ...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867533</th>\n",
       "      <td>0x2156a5</td>\n",
       "      <td>train</td>\n",
       "      <td>@lorettalrose Will you be displaying some &lt;LH&gt;...</td>\n",
       "      <td>trust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867534</th>\n",
       "      <td>0x2bb9d2</td>\n",
       "      <td>train</td>\n",
       "      <td>Lord, I &lt;LH&gt; in you.</td>\n",
       "      <td>trust</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1867535 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tweet_id identification  \\\n",
       "0        0x28cc61           test   \n",
       "1        0x29e452          train   \n",
       "2        0x2b3819          train   \n",
       "3        0x2db41f           test   \n",
       "4        0x2a2acc          train   \n",
       "...           ...            ...   \n",
       "1867530  0x227e25          train   \n",
       "1867531  0x293813          train   \n",
       "1867532  0x1e1a7e          train   \n",
       "1867533  0x2156a5          train   \n",
       "1867534  0x2bb9d2          train   \n",
       "\n",
       "                                                      text  emotion  \n",
       "0        @Habbo I've seen two separate colours of the e...      NaN  \n",
       "1        Huge Respect🖒 @JohnnyVegasReal talking about l...      joy  \n",
       "2        Yoooo we hit all our monthly goals with the ne...      joy  \n",
       "3        @FoxNews @KellyannePolls No serious self respe...      NaN  \n",
       "4        @KIDSNTS @PICU_BCH @uhbcomms @BWCHBoss Well do...    trust  \n",
       "...                                                    ...      ...  \n",
       "1867530  @BBCBreaking Such an inspirational talented pe...  disgust  \n",
       "1867531  And still #libtards won't get off the guy's ba...  sadness  \n",
       "1867532  When you sow #seeds of service or hospitality ...      joy  \n",
       "1867533  @lorettalrose Will you be displaying some <LH>...    trust  \n",
       "1867534                               Lord, I <LH> in you.    trust  \n",
       "\n",
       "[1867535 rows x 4 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge data_id, tweets_df, and emotion on 'tweet_id'\n",
    "merged_df = pd.merge(data_id, tweets_df, on='tweet_id', how='left')\n",
    "merged_df = pd.merge(merged_df, emotion, on='tweet_id', how='left')\n",
    "\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = merged_df[merged_df['identification'] == 'train']\n",
    "test_df = merged_df[merged_df['identification'] == 'test']\n",
    "test_df = test_df.drop(columns=['emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>identification</th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x29e452</td>\n",
       "      <td>train</td>\n",
       "      <td>Huge Respect🖒 @JohnnyVegasReal talking about l...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x2b3819</td>\n",
       "      <td>train</td>\n",
       "      <td>Yoooo we hit all our monthly goals with the ne...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x2a2acc</td>\n",
       "      <td>train</td>\n",
       "      <td>@KIDSNTS @PICU_BCH @uhbcomms @BWCHBoss Well do...</td>\n",
       "      <td>trust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0x2a8830</td>\n",
       "      <td>train</td>\n",
       "      <td>Come join @ambushman27 on #PUBG while he striv...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0x20b21d</td>\n",
       "      <td>train</td>\n",
       "      <td>@fanshixieen2014 Blessings!My #strength little...</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867530</th>\n",
       "      <td>0x227e25</td>\n",
       "      <td>train</td>\n",
       "      <td>@BBCBreaking Such an inspirational talented pe...</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867531</th>\n",
       "      <td>0x293813</td>\n",
       "      <td>train</td>\n",
       "      <td>And still #libtards won't get off the guy's ba...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867532</th>\n",
       "      <td>0x1e1a7e</td>\n",
       "      <td>train</td>\n",
       "      <td>When you sow #seeds of service or hospitality ...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867533</th>\n",
       "      <td>0x2156a5</td>\n",
       "      <td>train</td>\n",
       "      <td>@lorettalrose Will you be displaying some &lt;LH&gt;...</td>\n",
       "      <td>trust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867534</th>\n",
       "      <td>0x2bb9d2</td>\n",
       "      <td>train</td>\n",
       "      <td>Lord, I &lt;LH&gt; in you.</td>\n",
       "      <td>trust</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1455563 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tweet_id identification  \\\n",
       "1        0x29e452          train   \n",
       "2        0x2b3819          train   \n",
       "4        0x2a2acc          train   \n",
       "5        0x2a8830          train   \n",
       "6        0x20b21d          train   \n",
       "...           ...            ...   \n",
       "1867530  0x227e25          train   \n",
       "1867531  0x293813          train   \n",
       "1867532  0x1e1a7e          train   \n",
       "1867533  0x2156a5          train   \n",
       "1867534  0x2bb9d2          train   \n",
       "\n",
       "                                                      text       emotion  \n",
       "1        Huge Respect🖒 @JohnnyVegasReal talking about l...           joy  \n",
       "2        Yoooo we hit all our monthly goals with the ne...           joy  \n",
       "4        @KIDSNTS @PICU_BCH @uhbcomms @BWCHBoss Well do...         trust  \n",
       "5        Come join @ambushman27 on #PUBG while he striv...           joy  \n",
       "6        @fanshixieen2014 Blessings!My #strength little...  anticipation  \n",
       "...                                                    ...           ...  \n",
       "1867530  @BBCBreaking Such an inspirational talented pe...       disgust  \n",
       "1867531  And still #libtards won't get off the guy's ba...       sadness  \n",
       "1867532  When you sow #seeds of service or hospitality ...           joy  \n",
       "1867533  @lorettalrose Will you be displaying some <LH>...         trust  \n",
       "1867534                               Lord, I <LH> in you.         trust  \n",
       "\n",
       "[1455563 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>identification</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x28cc61</td>\n",
       "      <td>test</td>\n",
       "      <td>@Habbo I've seen two separate colours of the e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x2db41f</td>\n",
       "      <td>test</td>\n",
       "      <td>@FoxNews @KellyannePolls No serious self respe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0x2466f6</td>\n",
       "      <td>test</td>\n",
       "      <td>Looking for a new car, and it says 1 lady owne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0x23f9e9</td>\n",
       "      <td>test</td>\n",
       "      <td>@cineworld “only the brave” just out and fount...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0x1fb4e1</td>\n",
       "      <td>test</td>\n",
       "      <td>Felt like total dog 💩 going into open gym and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867495</th>\n",
       "      <td>0x2c4dc2</td>\n",
       "      <td>test</td>\n",
       "      <td>6 year old walks in astounded. Mum! Look how b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867496</th>\n",
       "      <td>0x31be7c</td>\n",
       "      <td>test</td>\n",
       "      <td>Only one week to go until the #inspiringvolunt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867500</th>\n",
       "      <td>0x1ca58e</td>\n",
       "      <td>test</td>\n",
       "      <td>I just got caught up with the manga for \"My He...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867515</th>\n",
       "      <td>0x35c8ba</td>\n",
       "      <td>test</td>\n",
       "      <td>Speak only when spoken to and make hot ass mus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867518</th>\n",
       "      <td>0x1d941b</td>\n",
       "      <td>test</td>\n",
       "      <td>Know what you want and go for it. Fuck everyon...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>411972 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tweet_id identification  \\\n",
       "0        0x28cc61           test   \n",
       "3        0x2db41f           test   \n",
       "15       0x2466f6           test   \n",
       "23       0x23f9e9           test   \n",
       "31       0x1fb4e1           test   \n",
       "...           ...            ...   \n",
       "1867495  0x2c4dc2           test   \n",
       "1867496  0x31be7c           test   \n",
       "1867500  0x1ca58e           test   \n",
       "1867515  0x35c8ba           test   \n",
       "1867518  0x1d941b           test   \n",
       "\n",
       "                                                      text  \n",
       "0        @Habbo I've seen two separate colours of the e...  \n",
       "3        @FoxNews @KellyannePolls No serious self respe...  \n",
       "15       Looking for a new car, and it says 1 lady owne...  \n",
       "23       @cineworld “only the brave” just out and fount...  \n",
       "31       Felt like total dog 💩 going into open gym and ...  \n",
       "...                                                    ...  \n",
       "1867495  6 year old walks in astounded. Mum! Look how b...  \n",
       "1867496  Only one week to go until the #inspiringvolunt...  \n",
       "1867500  I just got caught up with the manga for \"My He...  \n",
       "1867515  Speak only when spoken to and make hot ass mus...  \n",
       "1867518  Know what you want and go for it. Fuck everyon...  \n",
       "\n",
       "[411972 rows x 3 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to pickle file\n",
    "train_df.to_pickle(\"train_df.pkl\") \n",
    "test_df.to_pickle(\"test_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a pickle file\n",
    "train_df = pd.read_pickle(\"train_df.pkl\")\n",
    "test_df = pd.read_pickle(\"test_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_df['emotion'].value_counts(ascending=True).plot.barh()\n",
    "plt.title('Emotion Distribution in Train Data')\n",
    "plt.ylabel(None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenize & Label Encode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I use AutoTokenizer in Hugging Face Transformers to select tokenizer that matches the pretrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-23 15:55:04.418002: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1732348504.442095   26677 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1732348504.449457   26677 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-23 15:55:04.471766: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/s113062513/miniconda3/envs/dm/lib/python3.9/site-packages/transformers/convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"FacebookAI/roberta-base\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-base\")\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "encoder = LabelEncoder().fit(train_df['emotion'])\n",
    "num_labels = len(encoder.classes_)\n",
    "\n",
    "# Tokenize the dataset\n",
    "def tokenize(batch):\n",
    "\t#tokenized_text = tokenizer(batch['text'], padding=True, truncation=True)\n",
    "\ttokenized_text = tokenizer(batch['text'], truncation=True)\n",
    "\tbatch.update(tokenized_text)\n",
    "\tbatch['label'] = encoder.transform(batch['emotion'])\n",
    "\treturn batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# Create a dataset from the train dataframe\n",
    "train_dataset = Dataset.from_pandas(train_df, preserve_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d58dadcf0c7434682da1624ec89ab45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1455563 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = train_dataset.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['tweet_id', 'identification', 'text', 'emotion', 'input_ids', 'token_type_ids', 'attention_mask', 'label'],\n",
       "    num_rows: 1455563\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ff7b31fc0dd46eea3aa2c61c9bfb1cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1455563 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save train_dataset to disk\n",
    "train_dataset.save_to_disk(\"train_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.load_from_disk(\"train_dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tweet_id', 'identification', 'text', 'emotion', 'input_ids', 'token_type_ids', 'attention_mask', 'label'],\n",
       "        num_rows: 1310006\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['tweet_id', 'identification', 'text', 'emotion', 'input_ids', 'token_type_ids', 'attention_mask', 'label'],\n",
       "        num_rows: 145557\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_val_dataset = train_dataset.train_test_split(test_size=0.1) #0.2\n",
    "train_val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.metrics import accuracy_score, f1_score\n",
    "import evaluate\n",
    "\n",
    "accuracy_metric = evaluate.load('accuracy')\n",
    "f1_metric = evaluate.load('f1')\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    accuracy = accuracy_metric.compute(predictions=predictions, references=labels)\n",
    "    f1 = f1_metric.compute(predictions=predictions, references=labels, average='macro')\n",
    "    return {**accuracy, **f1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up training arguments such as epochs, batch size, fp16, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import evaluate\n",
    "from transformers import Trainer, TrainingArguments, AutoModelForSequenceClassification\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "#model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=num_labels)\n",
    "#model = AutoModelForSequenceClassification.from_pretrained(\"FacebookAI/roberta-base\", num_labels=num_labels)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"microsoft/deberta-v3-base\", num_labels=num_labels)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='results_deberta_v3',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=32, #32\n",
    "    per_device_eval_batch_size=32, #32\n",
    "    eval_strategy='steps',\n",
    "    eval_steps=10000, #10000\n",
    "    save_strategy='steps',\n",
    "    save_steps=10000, #10000\n",
    "    logging_steps=1000,\n",
    "    save_total_limit=5,\n",
    "    load_best_model_at_end=False, #True\n",
    "    fp16=True,\n",
    "    torch_compile=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_val_dataset['train'],\n",
    "    eval_dataset=train_val_dataset['test'],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='122814' max='122814' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [122814/122814 3:06:12, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>1.043600</td>\n",
       "      <td>1.073736</td>\n",
       "      <td>0.616920</td>\n",
       "      <td>0.520065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.997300</td>\n",
       "      <td>0.984549</td>\n",
       "      <td>0.652727</td>\n",
       "      <td>0.559136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.961100</td>\n",
       "      <td>0.947641</td>\n",
       "      <td>0.663630</td>\n",
       "      <td>0.579049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.940600</td>\n",
       "      <td>0.922378</td>\n",
       "      <td>0.665512</td>\n",
       "      <td>0.587842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>0.848500</td>\n",
       "      <td>0.921442</td>\n",
       "      <td>0.673028</td>\n",
       "      <td>0.596772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60000</td>\n",
       "      <td>0.843100</td>\n",
       "      <td>0.901535</td>\n",
       "      <td>0.680757</td>\n",
       "      <td>0.604364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70000</td>\n",
       "      <td>0.838200</td>\n",
       "      <td>0.890829</td>\n",
       "      <td>0.684502</td>\n",
       "      <td>0.606844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80000</td>\n",
       "      <td>0.819800</td>\n",
       "      <td>0.878546</td>\n",
       "      <td>0.685175</td>\n",
       "      <td>0.610104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90000</td>\n",
       "      <td>0.707500</td>\n",
       "      <td>0.925113</td>\n",
       "      <td>0.685690</td>\n",
       "      <td>0.613653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100000</td>\n",
       "      <td>0.695800</td>\n",
       "      <td>0.922463</td>\n",
       "      <td>0.687607</td>\n",
       "      <td>0.615049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110000</td>\n",
       "      <td>0.689700</td>\n",
       "      <td>0.914236</td>\n",
       "      <td>0.690733</td>\n",
       "      <td>0.618390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120000</td>\n",
       "      <td>0.678100</td>\n",
       "      <td>0.913216</td>\n",
       "      <td>0.691653</td>\n",
       "      <td>0.618912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=122814, training_loss=0.8497993108560633, metrics={'train_runtime': 11243.2462, 'train_samples_per_second': 349.545, 'train_steps_per_second': 10.923, 'total_flos': 9.854386462421808e+16, 'train_loss': 0.8497993108560633, 'epoch': 3.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer.save_model(\"model_bert_uncased\")\n",
    "#trainer.save_model(\"model_roberta_base_3epoch\")\n",
    "trainer.save_model(\"model_deberta_v3_base_3epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>grad_norm</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_accuracy</th>\n",
       "      <th>eval_f1</th>\n",
       "      <th>eval_runtime</th>\n",
       "      <th>eval_samples_per_second</th>\n",
       "      <th>eval_steps_per_second</th>\n",
       "      <th>train_runtime</th>\n",
       "      <th>train_samples_per_second</th>\n",
       "      <th>train_steps_per_second</th>\n",
       "      <th>total_flos</th>\n",
       "      <th>train_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.4759</td>\n",
       "      <td>3.570094</td>\n",
       "      <td>4.959369e-05</td>\n",
       "      <td>0.024427</td>\n",
       "      <td>1000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.2633</td>\n",
       "      <td>4.972721</td>\n",
       "      <td>4.918657e-05</td>\n",
       "      <td>0.048854</td>\n",
       "      <td>2000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.1809</td>\n",
       "      <td>3.994900</td>\n",
       "      <td>4.877986e-05</td>\n",
       "      <td>0.073282</td>\n",
       "      <td>3000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.1312</td>\n",
       "      <td>3.617017</td>\n",
       "      <td>4.837315e-05</td>\n",
       "      <td>0.097709</td>\n",
       "      <td>4000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.1089</td>\n",
       "      <td>3.726475</td>\n",
       "      <td>4.796603e-05</td>\n",
       "      <td>0.122136</td>\n",
       "      <td>5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.6781</td>\n",
       "      <td>5.301532</td>\n",
       "      <td>1.163955e-06</td>\n",
       "      <td>2.931262</td>\n",
       "      <td>120000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.931262</td>\n",
       "      <td>120000</td>\n",
       "      <td>0.913216</td>\n",
       "      <td>0.691653</td>\n",
       "      <td>0.618912</td>\n",
       "      <td>121.6741</td>\n",
       "      <td>1196.286</td>\n",
       "      <td>37.387</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0.6767</td>\n",
       "      <td>6.411352</td>\n",
       "      <td>7.568355e-07</td>\n",
       "      <td>2.955689</td>\n",
       "      <td>121000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0.6824</td>\n",
       "      <td>5.851131</td>\n",
       "      <td>3.497158e-07</td>\n",
       "      <td>2.980116</td>\n",
       "      <td>122000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>122814</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11243.2462</td>\n",
       "      <td>349.545</td>\n",
       "      <td>10.923</td>\n",
       "      <td>9.854386e+16</td>\n",
       "      <td>0.849799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>135 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  grad_norm  learning_rate     epoch    step  eval_loss  \\\n",
       "0    1.4759   3.570094   4.959369e-05  0.024427    1000        NaN   \n",
       "1    1.2633   4.972721   4.918657e-05  0.048854    2000        NaN   \n",
       "2    1.1809   3.994900   4.877986e-05  0.073282    3000        NaN   \n",
       "3    1.1312   3.617017   4.837315e-05  0.097709    4000        NaN   \n",
       "4    1.1089   3.726475   4.796603e-05  0.122136    5000        NaN   \n",
       "..      ...        ...            ...       ...     ...        ...   \n",
       "130  0.6781   5.301532   1.163955e-06  2.931262  120000        NaN   \n",
       "131     NaN        NaN            NaN  2.931262  120000   0.913216   \n",
       "132  0.6767   6.411352   7.568355e-07  2.955689  121000        NaN   \n",
       "133  0.6824   5.851131   3.497158e-07  2.980116  122000        NaN   \n",
       "134     NaN        NaN            NaN  3.000000  122814        NaN   \n",
       "\n",
       "     eval_accuracy   eval_f1  eval_runtime  eval_samples_per_second  \\\n",
       "0              NaN       NaN           NaN                      NaN   \n",
       "1              NaN       NaN           NaN                      NaN   \n",
       "2              NaN       NaN           NaN                      NaN   \n",
       "3              NaN       NaN           NaN                      NaN   \n",
       "4              NaN       NaN           NaN                      NaN   \n",
       "..             ...       ...           ...                      ...   \n",
       "130            NaN       NaN           NaN                      NaN   \n",
       "131       0.691653  0.618912      121.6741                 1196.286   \n",
       "132            NaN       NaN           NaN                      NaN   \n",
       "133            NaN       NaN           NaN                      NaN   \n",
       "134            NaN       NaN           NaN                      NaN   \n",
       "\n",
       "     eval_steps_per_second  train_runtime  train_samples_per_second  \\\n",
       "0                      NaN            NaN                       NaN   \n",
       "1                      NaN            NaN                       NaN   \n",
       "2                      NaN            NaN                       NaN   \n",
       "3                      NaN            NaN                       NaN   \n",
       "4                      NaN            NaN                       NaN   \n",
       "..                     ...            ...                       ...   \n",
       "130                    NaN            NaN                       NaN   \n",
       "131                 37.387            NaN                       NaN   \n",
       "132                    NaN            NaN                       NaN   \n",
       "133                    NaN            NaN                       NaN   \n",
       "134                    NaN     11243.2462                   349.545   \n",
       "\n",
       "     train_steps_per_second    total_flos  train_loss  \n",
       "0                       NaN           NaN         NaN  \n",
       "1                       NaN           NaN         NaN  \n",
       "2                       NaN           NaN         NaN  \n",
       "3                       NaN           NaN         NaN  \n",
       "4                       NaN           NaN         NaN  \n",
       "..                      ...           ...         ...  \n",
       "130                     NaN           NaN         NaN  \n",
       "131                     NaN           NaN         NaN  \n",
       "132                     NaN           NaN         NaN  \n",
       "133                     NaN           NaN         NaN  \n",
       "134                  10.923  9.854386e+16    0.849799  \n",
       "\n",
       "[135 rows x 16 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(trainer.state.log_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(trainer.state.log_history).to_csv('log_history_deberta_v3_5epoch.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('dm-2024-isa-5810-lab-2-homework/sampleSubmission.csv')\n",
    "test_df = test_df.set_index('tweet_id').loc[sample_submission['id']].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "\t#tokenized_text = tokenizer(batch['text'], padding=True, truncation=True)\n",
    "\ttokenized_text = tokenizer(batch['text'], truncation=True)\n",
    "\tbatch.update(tokenized_text)\n",
    "\n",
    "\treturn batch\n",
    "\n",
    "# Create a dataset from the train dataframe\n",
    "test_dataset = Dataset.from_pandas(test_df, preserve_index=False)\n",
    "test_dataset = test_dataset.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.save_to_disk(\"test_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = Dataset.load_from_disk(\"test_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions, labels, metrics = trainer.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['joy', 'joy', 'sadness', ..., 'disgust', 'joy', 'sadness'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels = np.argmax(predictions, axis=-1)\n",
    "predicted_emotions = encoder.inverse_transform(predicted_labels)\n",
    "predicted_emotions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame for the submission\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': sample_submission['id'],\n",
    "    'emotion': predicted_emotions\n",
    "})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "#submission_df.to_csv('submission.csv', index=False)\n",
    "submission_df.to_csv('submission_deberta_v3_3epoch.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data_collator\n",
    "del trainer\n",
    "del model\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I train several pre-trained Transformer models available on Hugging Face including BERT, RoBERTa, and DeBERTa v3. By utilizing the powerful BERT models and tokenizers, I am able to obtain fairly good results without feature engineering steps, significantly reduce the efforts needed.\n",
    "\n",
    "However, Transformer based models require some amount of GPU memory and take time to train. Results also show that the models tend to overfit the training dataset when train epochs > 3.\n",
    "\n",
    "To further enhance the performance, one can search for feature engineering techniques that suit BERT models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
